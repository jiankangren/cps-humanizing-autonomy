\subsection{Research Thrust 1: Behavior modeling}
\label{sec:behaviour}

 The ability to (1) detect, (2) assess and (3) control a person’s emotions has been identified to be the predictor of success in relating to the people around us. By being able to read other’s “emotional cues,” not only we can better understand how they are feeling at a given time, but it also helps us to predict how they will respond in different scenarios. Research suggests that emotions are normally associated with specific events or occurrences  (cite), and they can significantly influence our thoughts and behaviors. Additionally, we can use reason to evaluate our emotions, interpret them, and reassess our initial reactions to them. Therefore, by detecting certain events and occurrences, we may be able to assess and predict individual emotional states and use reason to soften their impact or “shift” their meaning. If the vision for the future AVs is to build "human-like" trust with the passenger(s), just like humans, AVs should be able to detect, assess, and control the passenger(s) emotions in real-time. 
 
\AH{add a transition sentence} In this project, we aim to better understand what environmental factors influence passenger(s) emotions and how these emotions influence driving behaviors. Specifically, we are interested in formally characterizing emotions through a “context-dependence” approach, where spatial and temporal information can be automatically detected, analyzed, and interpreted. Through instrumentation of a number of manual and semi-autonomous \AH{can we say autonomous cars? or should we just leave it at manual cars} vehicles, we will collect environmental data with ambient-condition sensors (i.e., thermal, indoor and outdoor noise levels, and lighting) in parallel with user-specific behavioral, emotional and physiological traits through cameras, wearables (e.g. smartwatch), pressure sensors (seat and steering wheel). Through facial recognition algorithms as well as application and social media data (e.g., Spotify, Pandora) we will monitor and identify changes in passenger emotions and behaviors. Through statistical analysis and machine learning techniques, we will identify models of behavioral and emotional traits in specific contextual and environmental settings. The specific research questions that will be addressed through this approach include: 
\begin{enumerate}
    \item What is the relationship between environmental/contextual settings and passenger(s) emotions and behaviors?
    \item What is the taxonomy of behaviors and emotions in driving?
    \item How behavior and emotions can non-intrusively and with least number of sensors be accurately detected?
    \item What are environmental and social factors that can gain your attention? (research on signs)
    \item Do people "trust" certain specific behaviors or conditions? \AH{for instance, do you trust your own behavior more than another type of driving behavior}? 

\end{enumerate}

As a first approach, we plan to observe trends in our data that both reveal (1) factors that influence specific human emotions and (2) the downstream consequences of particular emotions on their behaviors. For example, we will aim to understand what environmental (e.g., weather, thermal conditions, lighting, noise) and social factors (e.g., social interaction), physiological factors (e.g.,arm movement) trigger particular emotions. Through this approach, we will also be able to develop a database of  emotions, behaviors and environmental changes. %as there exists a limited number of emotional models and databases available to the public and the research community.
As it may be difficult to often identify triggers to particular emotions (i.e., passenger may appear already experiencing a particular emotion), we plan to evaluate which behavioral outcomes can be used as cues for particular emotions. For example, we may learn that when participants are feeling sad, they are more likely to deviate from their normal accelerating and decelerating behaviors or more likely to listen to certain genre of music. With this information, we will then assess if we can reliably predict particular emotions, given that a passenger behaved in a particular way. 

After having a better understanding of these factors, we aim to develop psychological interventions to (1) reduce the negative outcomes of experiencing particular emotions \AH{this will be updated} and (2) reduce the likelihood of passengers’ experiencing triggers that lead to emotions that have negative consequences (e.g., safety, trust). 


With this information as a cue, we can understand that there might be a need to intervene or provide some feedback to the passenger at that time. 


In this research, we will conduct real-life as well as simulation-based experimental studies to identify understand (1) the association between human emotional he causation of attributes and contextual interaction observed from each individual, (2) a taxonomy of emotional and behavioral traits as they relate to the internal and external triggers as well as personalized traits and (3) perspectives of trust in autonomous vehicles from real people, rather than working on assumptions, and (4) the intervention and communication strategies that could be automated by AV to meet passengers(s) need and enhance their "driving/journey" experience.


\AH{Modify this table if needed}

\begin{center}
    \begin{tabular}{ | l | l | l |}
    \hline
    Type &  Factors & Sensor/Algorithms \\ \hline
    \multirow{5}{*}{Environmental Sensing} & Speed & Automatic Pro \\
        & Location & GPS/Automatic Pro \\
        & indoor and outdoor conditions & cameras \\
        & Passengers' identity and count & cameras \\
        & Weather Conditions & Camera and weather database\\\hline
    \multirow{8}{*}{Human Sensing} & Face features & eye tracking, camera, facial recognition \\
        & Noise levels & noise-level sensors \\
        & Passenger voice & Voice recorder, Natural Language Processing \\
        & Brake and acceleration rate & Automatic Pro \\
        & Grip on steering wheel & pressure sensor \\
        & Music and other social media use & APIs (e.g., Spotify) \\
        & Social interaction & Camera and voice recorder \\ \hline
    
    \end{tabular}
\end{center}



\AH{add about how cars can enhance the driver emotions as well but selecting routes or choosing music or behaving in a certain way...}







%One of the most compelling benefits of emotion-aware vehicles is the ability to monitor drivers’ behavior and address potential safety concerns associated with facial expressions and mood.
%Identifying fatigue, distraction, and frustration to prevent accidents before they happen.
%If a self-driving car perceived emotional distress from passengers, it could drive more slowly or play soothing %music to assuage their anxiety.
%Autonomous driving machines adjust driving styles based on the passenger(s) non-verbal feedback.

%Human behavior and emotions are highly dynamic and are different among individuals based on their previous experiences, environmental factors (e.g., weather, lighting), societal factors, and internal factors (e.g., physiological changes). 

%Currently, AVs (as well as many other autonomous systems) lack in have any sensing and optimization capability according to passenger(s) real-time behavioral and emotional changes. . 



%Safety is not primarily just a functional consideration, it is also emotional. We propose that the issues of functional and emotional design for autonomous vehicles should be tackled together.
%For example, emotional down-regulation could be used when passengers might be facing an upsetting or frustrating situation – for instance, a delay in travel. Here the AV could sense the frustration and then down-regulate through voice prompts. When you’re jumping in and out of different AVs, a consistent and personal experience will be vital for successful adoption.
% We’re concerned with a person’s ability, and even right, to make their own decisions, and come and go as they please. Not about how clever cars are without human drivers. 




%Autonomous cars are not just about the technology. They are about freedom of mobility, and a whole set of experiences that will literally and figuratively move people in new ways.



%While the promise of self-driving cars is attractive, applying it in a meaningful and coherent way, where passenger(s) behaviors, preferences, and needs are considered, still remains a limitation and major challenge.


%Transparency and communication are critical to building trust. To establish user understanding of the system and its capabilities the interface must communicate clearly, and transparently - by revealing what the car sees, what the system is currently doing, what it intends to do in response to environmental conditions and why. 




\arsalan{Spill the magic dust Arsalan}